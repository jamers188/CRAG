# APIs
openai_api_key: "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"
openai_api_base: "https://api.openai.com/v1/chat/completions" # or your own proxy
google_api_key: "AIzaSyBXHrAngrjce0eBaDMrehZc-IiY8JI6ThQ"
tavily_api_key: "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"

# Ollama Config
run_local: "No" # must have ollama runnig in ur PC if Yes
local_llm: "openhermes" # mistral, llama2 ...

# Model Config
models: "openai"

# Document Config
doc_url: 
  - https://arxiv.org/abs/2406.04744
